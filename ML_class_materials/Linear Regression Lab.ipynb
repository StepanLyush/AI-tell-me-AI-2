{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOdr8rqnIgfZ85nu47x1Xdv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Linear Regression\n","\n"],"metadata":{"id":"B6dH4e2Yh44O"}},{"cell_type":"markdown","source":["# Data preparation\n"],"metadata":{"id":"qMopvgtAmgH0"}},{"cell_type":"code","source":["# This data set contains following columns:\n","\n","# 0   No                                      int64  \n","# 1   X1 house age                            float64\n","# 2   X2 distance to the nearest MRT station  float64\n","# 3   X3 number of convenience stores         int64  \n","# 4   X4 latitude                             float64\n","# 5   X5 longitude                            float64\n","# 6   Y house price of unit area              float64"],"metadata":{"id":"DZ6rxPp2EQcC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Lab assignment\n","\n","# Explore the dataset.\n","# Create and evaluete a simple linear regression model by selecting an independent variable that is most correlated with Y.\n","# Create and evaluete a multiple linear regression model by selecting 2 or 3 independent variables that are most correlated with Y.\n","  ## Take care about the correlations between the independent variables.\n","# Create a multiple linear regression model with diagnostics by selecting 2 or 3 independent variables that are most correlated with Y (the same as in the previous model).\n","  ## Take care about the correlations between the independent variables.\n","  ## Use statsmodels.api and statsmodels.formula.api is used for building and fitting the linear regression model with diagnostics features.\n","  ## Create the diagnostic plots.\n","# Create and evaluate a multiple linear regression model with diagnostics by selecting all independent variables except for No.\n","  ##  Check for mutlicollinearity\n","## Create and evaluate a multiple linear regression model with diagnostics by selecting all independent variables except for No\n","  ## and a variable with a square root of VIFs > 2 (calculated in the previous model)."],"metadata":{"id":"wbQXNhSJnluL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Data load from GitHub\n","# Load a csv file from GitHub by coping a raw csv link\n","import numpy as np\n","import pandas as pd\n","\n","#Visualization Libraries\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","url = 'https://raw.githubusercontent.com/suyashphatak23/Real-Estate-Price-Predictor/master/Real_estate.csv'\n","\n","df = pd.read_csv(url)\n","df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JpfuaEK0ew7-","executionInfo":{"status":"ok","timestamp":1682279525130,"user_tz":-120,"elapsed":305,"user":{"displayName":"Sonja DimitrijeviÄ‡","userId":"13192049832098734700"}},"outputId":"e1440472-69c9-4073-c434-18d7eaf90ffa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(414, 7)"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["# Dataset variables info\n"],"metadata":{"id":"lZx95GS_Uu76"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking if the dataset has missing values\n"],"metadata":{"id":"L1tcplHVKWRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Checking data\n","# First 5 rows\n"],"metadata":{"id":"PaVmn8w-stfz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Describing data\n"],"metadata":{"id":"7xXKMHmx6Vho"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Data visualization\n","\n","# Ploting the distribution of the target variable"],"metadata":{"id":"qyCyxBbuEvHn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Univariate Plots (Density Plots)"],"metadata":{"id":"T0nYXFpi4MF4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing correlation matrics"],"metadata":{"id":"0VGN2QUl9UZD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Visualizing the change in the variables"],"metadata":{"id":"rJgCwRwdM0kH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Linear Regression Models\n"],"metadata":{"id":"sGvUfZUDDbpi"}},{"cell_type":"code","source":["#@title Simple Linear Regression 1\n","\n","\n","# Splitting data\n"],"metadata":{"id":"NezxFOcBdDQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting train and test data\n","\n","\n","# Shape of the train and test sets"],"metadata":{"id":"zHAlR7lKrFEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initializing LinearRegression model\n","\n","\n","# Fitting the model\n"],"metadata":{"id":"cuvOP647r68-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retreiving the intercept\n"],"metadata":{"id":"6y4Kxo3PoUgi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retreiving the slope\n"],"metadata":{"id":"Q6HiFgRUpEvq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicting values for the train set\n","\n","\n","# Predicting values for the test set\n"],"metadata":{"id":"wtcUXhBDyppu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparing the predicted and actual values\n"],"metadata":{"id":"VQMfEtr046yN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Simple Linear Regression 1 Vizualization\n","\n","# Visualizing the comparison of the predicted and actual values\n"],"metadata":{"id":"u8qMAfGM-TYw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting a straight line with test data\n"],"metadata":{"id":"-yU78CpiBBSf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Simple Linear Regression 1 Evaluation\n","\n","\n","# Model evaluation for the training set\n","\n","# Computing (adjusted) r-squared with formulas from the theory\n","\n","\n","# another way to calculate r_squared (r2) using sklearn.metrics\n","# adj_r_squared1 = r2_score(y1_train, predicted_y1_train)\n","\n","# Using metrics api for MAE, MSE, RMSE\n"],"metadata":{"id":"_arIO8haAopa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Model evaluation for the test set\n","\n","# Computing (adjusted) r-squared with formulas from the theory\n","\n","\n","# another way to calculate r_squared (r2) using sklearn.metrics\n","# r_squared1 = r2_score(y1_test, pred_y1_test_array)\n","\n","# Using metrics api for MAE, MSE, RMSE\n"],"metadata":{"id":"yRbW0EmNrYYQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calculating the mean of the test Y to compare with RMSE\n","\n","\n","# Comparing RMSE with the mean of test medv\n"],"metadata":{"id":"1j9BOdFk7lVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 2\n","# Include 2 or 3 indipendent variables that are most correlated with Y. Take care about their mutual correlations.\n","\n","# Splitting data X2 and y2\n"],"metadata":{"id":"HqUa1p6JIUPh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting train and test data\n","\n","\n","# Shape of the train and test sets\n"],"metadata":{"id":"5aQDdEeqyGmW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Initializing LinearRegression model\n","\n","\n","# Fitting the model\n"],"metadata":{"id":"jqFNl0Qrynky"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retreiving the intercept\n"],"metadata":{"id":"du5-m4wmy1d0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Retreiving the slope\n"],"metadata":{"id":"xMvMgl_Hy92d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicting values - train dataset\n","\n","\n","# Predicting values - test dataset\n"],"metadata":{"id":"g-_gKck1zDxF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparing the predicted and actual values\n"],"metadata":{"id":"-hZC9vvg1z0i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 2 Vizualization\n","\n","# Visualizing the comparison of the predicted and actual values\n"],"metadata":{"id":"X0Qc4XMX2Ob8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 2 Evaluation\n","\n","\n","# Training set\n","# Computing (adjusted) r-squared with formulas from the theory\n","\n","\n","# another way to calculate r_squared (r2) using sklearn.metrics\n","# r2 = r2_score(y2_train, pred_y2_train_array)\n","\n","# Using metrics api for MAE, MSE, RMSE\n","\n"],"metadata":{"id":"kmkV56Xl5SRA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Test set\n","\n","# Computing (adjusted) r-squared with formulas from the theory\n","\n","\n","# another way to calculate r_squared (r2) using sklearn.metrics\n","# r2 = r2_score(y2_test, pred_y2_test_array)\n","\n","# Using metrics api for MAE, MSE, RMSE\n"],"metadata":{"id":"gsiqgrVOFThD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Comparison of metrics (test datasets)\n"],"metadata":{"id":"klaWgTw55xMJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 3 with Diagnostics\n","# Use the same variable like in the previous model (Multiple Linear Regression 3)\n","\n","# statsmodels.api and statsmodels.formula.api is used for building and fitting the linear regression model\n","# due to its diagnostics features.\n","\n","\n","# The diagnostic plots are run on the trained regression model before testing the model."],"metadata":{"id":"mTnzQpGn5xCV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Plotting residuals vs. fitted values for checking the linearity assumption between\n","# the dependent and indipendent variables\n","\n"],"metadata":{"id":"owHLy0L1jdLX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Quantile - Quantile (Q-Q) plot for checking if the residuals follow a normal distribution\n"],"metadata":{"id":"O3I5JxQPoXp7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Scale - Location plot for checking the assumption of the equal variance of the\n","# residuals, homoskedasticity\n","\n"],"metadata":{"id":"kb7Dgug8VgoI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Residuals vs. Leverage for spotting the presence of high leverage points\n"],"metadata":{"id":"_5nQVGmutJ04"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Density plot - the predicted against actual values\n"],"metadata":{"id":"_1ZykOUgkvou"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 4 with Diagnostics\n","# Use all X variable except for No\n","\n","# Splitting data\n"],"metadata":{"id":"p95IWTJC9Fgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting train and test data\n","\n","\n","# Shape of the train and test sets\n"],"metadata":{"id":"PIGszetSuJvO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building and fitting the linear regression model using statsmodels.api\n","## sm.add_constant adds an intercept, which is not included by default\n"],"metadata":{"id":"dGUIpPAwwxGQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicting values - test dataset\n"],"metadata":{"id":"NliLWUnk9xUZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Comparing the predicted and actual values\n"],"metadata":{"id":"P9wEVI50AJCv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 4 Evaluation\n","# Test set\n","\n","# Computing (adjusted) r-squared with formulas from the theory\n","\n","\n","\n","\n","# Using metrics api for MAE, MSE, RMSE\n"],"metadata":{"id":"-erVN-FjK21K"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking for mutlicollinearity\n","\n","# Collinearity refers to the situation when 2 or more predictors are highly related to \n","# one another. A simple way to detect collinearity is to look at the correlation matrix\n","# of the predictors. However, it is possible that collinearity exist between 3 or\n","# more variables, even if no pair of variables has a particularly high correlation.\n","# This is known as multicollinearity. One of the assumptions of the multiple linear\n","# regression is the absence of the multicollinearity. \n","\n","# One way of checking multicollinearity is to compute the Variance Inflation Factor (VIF)\n","\n","\n","# For each X, calculate VIF and save in dataframe\n","\n","\n","# Add const because the algorithm requires it\n","\n","\n","# As a rule of thumb, variables having a square root of VIFs > 2 are problematic.\n","\n","# Finding square roots of VIFs\n"],"metadata":{"id":"X6ogkEWncIbe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 5 with Diagnostics\n","# It should be proceded by exluding variables with the highest VIF value one by one.\n","\n","\n","# Splitting data (after removing chas, tax and medv from predictors)\n"],"metadata":{"id":"Ew418u-SnAZ3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Splitting train and test data\n","\n","\n","# Shape of the train and test sets\n"],"metadata":{"id":"p1iDZKng7yYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Building and fitting the linear regression model using statsmodels.api\n","## sm.add_constant adds an intercept, which is not included by default\n"],"metadata":{"id":"qFhx6ZJn-RUA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Checking for mutlicollinearity\n","\n","# For each X, calculate VIF and save in dataframe\n","\n","\n","# Adding const because the algorithm requires it\n","\n","\n","# As a rule of thumb, variables having a square root of VIFs > 2 are problematic.\n","\n","# Finding square roots of VIFs\n"],"metadata":{"id":"VICNvLlrBOwq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicting values - test dataset\n"],"metadata":{"id":"N2wVTFnD1VAa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title Multiple Linear Regression 5 Evaluation\n","# Test set\n","\n","# Computing (adjusted) r-squared with formulas from the theory\n","\n","\n","# another way to calculate r_squared (r2) using sklearn.metrics\n","\n","\n","# Using metrics api for MAE, MSE, RMSE\n"],"metadata":{"id":"KInMujlW0yQY"},"execution_count":null,"outputs":[]}]}